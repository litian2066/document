# 领导者选举源码分析

## 服务启动的时候

### 理论部分

1. 先投给自己一票`<sid, zxid>`
2. 然后服务器相互传递自己的投票箱<类似数组的结构>内容进行比较：通过zxid的大小来比较，如果zxid大小一样就通过myid进行比较
   	A:{<A, 1>} -> {<A, 1>, <B, 1>} -> {<B, 2>,<B, 2>}
   B:{<B, 2>} -> {<B, 2>, <A, 1>} -> {<B, 2>,<B, 2>}
   由于有过半机制，就算有3台服务器，启动两台也能启动选出领导

### 源码分析

启动在`QuorumPeerMain`类中的main方法 ->`runFromConfig(config);` ->加载配置文件 -> `QuorumPeer`类的`start()`

```java
@Override
public synchronized void start() {
    // 加载数据
    loadDataBase();
    // 开启读取数据线程
    cnxnFactory.start();
    // 进行领导者选举，确定服务器的角色，再针对不同的服务器角色进行初始化，但事实上并没有在这里确认
    // 这个方法只是进行一些初始化的操作
    startLeaderElection();
    // 本类的run方法 其实在这个方法进行zab协议以及领导者选举
    super.start();
}
```

`startLeaderElection()`

````java
synchronized public void startLeaderElection() {
    try {
        // 生成投票，投给自己
        currentVote = new Vote(myid, getLastLoggedZxid(), getCurrentEpoch());
       
    } catch(IOException e) {
        RuntimeException re = new RuntimeException(e.getMessage());
        re.setStackTrace(e.getStackTrace());
        throw re;
    }
    for (QuorumServer p : getView().values()) {
        if (p.id == myid) {
            myQuorumAddr = p.addr;
            break;
        }
    }
    if (myQuorumAddr == null) {
        throw new RuntimeException("My id " + myid + " not in the peer list");
    }
    if (electionType == 0) {
        try {
            udpSocket = new DatagramSocket(myQuorumAddr.getPort());
            responder = new ResponderThread();
            responder.start();
        } catch (SocketException e) {
            throw new RuntimeException(e);
        }
    }
    this.electionAlg = createElectionAlgorithm(electionType);
}
````

````java

        public Vote(long id, 
                    long zxid, 
                    long peerEpoch) {
            this.version = 0x0;
            this.id = id; // myid
            this.zxid = zxid;
            this.electionEpoch = -1; // 选举周期，每次选举+1，按道理是从0开始，可以理解第几轮
            // 届号,如果有届号就先判断届号大，就不用比较zxid
            // 如果收到其他服务器的届号比自己大就把自己的届号更新为对方的届号，在继续循环
            this.peerEpoch = peerEpoch;  
            this.state = ServerState.LOOKING;
    	}
     
````

````java
protected Election createElectionAlgorithm(int electionAlgorithm){
    Election le=null;

    //TODO: use a factory rather than a switch
    switch (electionAlgorithm) {
        case 0:
            le = new LeaderElection(this);
            break;
        case 1:
            le = new AuthFastLeaderElection(this);
            break;
        case 2:
            le = new AuthFastLeaderElection(this, true);
            break;
        case 3:
            // 初始化负责各台服务器之间的底层Leader选举过程中的网络通信。
            qcm = createCnxnManager();
            QuorumCnxManager.Listener listener = qcm.listener;
            if(listener != null){
                // 启动线程
                listener.start();
                // 默认用的是FastLeaderElection
                le = new FastLeaderElection(this, qcm);
            } else {
                LOG.error("Null listener when initializing cnx manager");
            }
            break;
        default:
            assert false;
    }
    return le;
}
````

选举依旧需要依赖socket 所以我们来看下`createCnxnManager`代码

`createCnxnManager`是传输层，主要控制传输

````java
public QuorumCnxManager(final long mySid,
                            Map<Long,QuorumPeer.QuorumServer> view,
                            QuorumAuthServer authServer,
                            QuorumAuthLearner authLearner,
                            int socketTimeout,
                            boolean listenOnAllIPs,
                            int quorumCnxnThreadsSize,
                            boolean quorumSaslAuthEnabled,
                            ConcurrentHashMap<Long, SendWorker> senderWorkerMap) {
        // 负责传输层传输数据
        this.senderWorkerMap = senderWorkerMap;
	
        this.recvQueue = new ArrayBlockingQueue<Message>(RECV_CAPACITY);
        this.queueSendMap = new ConcurrentHashMap<Long, ArrayBlockingQueue<ByteBuffer>>();
        this.lastMessageSent = new ConcurrentHashMap<Long, ByteBuffer>();
        String cnxToValue = System.getProperty("zookeeper.cnxTimeout");
        if(cnxToValue != null){
            this.cnxTO = Integer.parseInt(cnxToValue);
        }

        this.mySid = mySid;
        this.socketTimeout = socketTimeout;
        this.view = view;
        this.listenOnAllIPs = listenOnAllIPs;

        initializeAuth(mySid, authServer, authLearner, quorumCnxnThreadsSize,
                quorumSaslAuthEnabled);

        // Starts listener thread that waits for connection requests 
        listener = new Listener();
    }
````

初始化属性

```java
final ConcurrentHashMap<Long, SendWorker> senderWorkerMap;  // 每台服务器对应的SendWorker，负责发送数据
// 向其他服务器发送数据的队列
final ConcurrentHashMap<Long, ArrayBlockingQueue<ByteBuffer>> queueSendMap;
final ConcurrentHashMap<Long, ByteBuffer> lastMessageSent; // 发送给每台服务器最近的消息

public final ArrayBlockingQueue<Message> recvQueue;  // 本台服务器接收到的消息
```

通过上面可以得知，每台服务器都有这3个属性，2个map和一个阻塞队列，map的key都是myid

通过上面代码可以看到创建了一个listener线程，回到主流程，将listener线程启动

````java
listener.start();
````

我们来看看listener的run()方法

`````java
public void run() {
    int numRetries = 0;
    InetSocketAddress addr;
    while((!shutdown) && (numRetries < 3)){
        try {
            ss = new ServerSocket();
            ss.setReuseAddress(true);
            if (listenOnAllIPs) {
                int port = view.get(QuorumCnxManager.this.mySid)
                    .electionAddr.getPort();
                addr = new InetSocketAddress(port);
            } else {
                addr = view.get(QuorumCnxManager.this.mySid)
                    .electionAddr;
            }
            LOG.info("My election bind port: " + addr.toString());
            setName(view.get(QuorumCnxManager.this.mySid)
                    .electionAddr.toString());
            ss.bind(addr);
            while (!shutdown) {
                Socket client = ss.accept(); //
                setSockOpts(client);
                LOG.info("Received connection request "
                         + client.getRemoteSocketAddress());

                // Receive and handle the connection request
                // asynchronously if the quorum sasl authentication is
                // enabled. This is required because sasl server
                // authentication process may take few seconds to finish,
                // this may delay next peer connection requests.
                if (quorumSaslAuthEnabled) {
                    receiveConnectionAsync(client);
                } else {
                    // 一个socket调用一次
                    receiveConnection(client);
                }

                numRetries = 0;
            }
        } catch (IOException e) {
            LOG.error("Exception while listening", e);
            numRetries++;
            try {
                ss.close();
                Thread.sleep(1000);
            } catch (IOException ie) {
                LOG.error("Error closing server socket", ie);
            } catch (InterruptedException ie) {
                LOG.error("Interrupted while sleeping. " +
                          "Ignoring exception", ie);
            }
        }
    }
    LOG.info("Leaving listener");
    if (!shutdown) {
        LOG.error("As I'm leaving the listener thread, "
                  + "I won't be able to participate in leader "
                  + "election any longer: "
                  + view.get(QuorumCnxManager.this.mySid).electionAddr);
    }
}
`````

````java
public void receiveConnection(final Socket sock) {
        DataInputStream din = null;
        try {
            din = new DataInputStream(
                    new BufferedInputStream(sock.getInputStream()));

            handleConnection(sock, din);
        } catch (IOException e) {
            LOG.error("Exception handling connection, addr: {}, closing server connection",
                     sock.getRemoteSocketAddress());
            closeSocket(sock);
        }
    }
````

````java
private void handleConnection(Socket sock, DataInputStream din)
            throws IOException {
        Long sid = null;
        try {
            // Read server id
            sid = din.readLong();
            if (sid < 0) { // this is not a server id but a protocol version (see ZOOKEEPER-1633)
                sid = din.readLong();

                // next comes the #bytes in the remainder of the message
                // note that 0 bytes is fine (old servers)
                int num_remaining_bytes = din.readInt();
                if (num_remaining_bytes < 0 || num_remaining_bytes > maxBuffer) {
                    LOG.error("Unreasonable buffer length: {}", num_remaining_bytes);
                    closeSocket(sock);
                    return;
                }
                byte[] b = new byte[num_remaining_bytes];

                // remove the remainder of the message from din
                int num_read = din.read(b);
                if (num_read != num_remaining_bytes) {
                    LOG.error("Read only " + num_read + " bytes out of " + num_remaining_bytes + " sent by server " + sid);
                }
            }
            if (sid == QuorumPeer.OBSERVER_ID) {
                /*
                 * Choose identifier at random. We need a value to identify
                 * the connection.
                 */
                sid = observerCounter.getAndDecrement();
                LOG.info("Setting arbitrary identifier to observer: " + sid);
            }
        } catch (IOException e) {
            closeSocket(sock);
            LOG.warn("Exception reading or writing challenge: " + e.toString());
            return;
        }

        // do authenticating learner
        LOG.debug("Authenticating learner server.id: {}", sid);
        authServer.authenticate(sock, din);

        //If wins the challenge, then close the new connection.
        // 如果我的sid大于对方的，则有我去连接他
        if (sid < this.mySid) {  // sid是对方的sid
            /*
             * This replica might still believe that the connection to sid is
             * up, so we have to shut down the workers before trying to open a
             * new connection.
             */
            SendWorker sw = senderWorkerMap.get(sid);
            if (sw != null) {
                sw.finish();
            }

            /*
             * Now we start a new connection
             */
            LOG.debug("Create new connection to server: " + sid);
            closeSocket(sock);
            connectOne(sid);

            // Otherwise start worker threads to receive data.
        } else {
            //  创建两个线程
            SendWorker sw = new SendWorker(sock, sid);
            RecvWorker rw = new RecvWorker(sock, din, sid, sw);
            sw.setRecv(rw);

            SendWorker vsw = senderWorkerMap.get(sid);
            
            if(vsw != null)
                vsw.finish();
            // 
            senderWorkerMap.put(sid, sw);
            queueSendMap.putIfAbsent(sid, new ArrayBlockingQueue<ByteBuffer>(SEND_CAPACITY));
            
            sw.start();
            rw.start();
            
            return;
        }
    }
````

由上可知，**小sid连接大的sid是不允许的**，接下来看上面创建的两个线程run()方法源码

SendWorker#run 从线程拿出队列，在从队列拿出数据，通过socket发送

````java
@Override
public void run() {
    threadCnt.incrementAndGet();
    try {
        /**
                 * If there is nothing in the queue to send, then we
                 * send the lastMessage to ensure that the last message
                 * was received by the peer. The message could be dropped
                 * in case self or the peer shutdown their connection
                 * (and exit the thread) prior to reading/processing
                 * the last message. Duplicate messages are handled correctly
                 * by the peer.
                 *
                 * If the send queue is non-empty, then we have a recent
                 * message than that stored in lastMessage. To avoid sending
                 * stale message, we should send the message in the send queue.
                 */
        // 从线程拿出队列
        ArrayBlockingQueue<ByteBuffer> bq = queueSendMap.get(sid);
        if (bq == null || isSendQueueEmpty(bq)) {
            ByteBuffer b = lastMessageSent.get(sid);
            if (b != null) {
                LOG.debug("Attempting to send lastMessage to sid=" + sid);
                send(b);
            }
        }
    } catch (IOException e) {
        LOG.error("Failed to send last message. Shutting down thread.", e);
        this.finish();
    }

    try {
        while (running && !shutdown && sock != null) {

            ByteBuffer b = null;
            try {
                // 取数据
                ArrayBlockingQueue<ByteBuffer> bq = queueSendMap
                    .get(sid);
                if (bq != null) {
                    b = pollSendQueue(bq, 1000, TimeUnit.MILLISECONDS);
                } else {
                    LOG.error("No queue of incoming messages for " +
                              "server " + sid);
                    break;
                }

                if(b != null){
                    lastMessageSent.put(sid, b);
                    // 通过socket发送数据
                    send(b);
                }
            } catch (InterruptedException e) {
                LOG.warn("Interrupted while waiting for message on queue",
                         e);
            }
        }
    } catch (Exception e) {
        LOG.warn("Exception when using channel: for id " + sid
                 + " my id = " + QuorumCnxManager.this.mySid
                 + " error = " + e);
    }
    this.finish();
    LOG.warn("Send worker leaving thread");
}
}
````

RecvWorker#run 接受数据，包装放入队列

````java
@Override
public void run() {
    threadCnt.incrementAndGet();
    try {
        while (running && !shutdown && sock != null) {
            /**
                     * Reads the first int to determine the length of the
                     * message
                     */
            int length = din.readInt();
            if (length <= 0 || length > PACKETMAXSIZE) {
                throw new IOException(
                    "Received packet with invalid packet: "
                    + length);
            }
            /**
                     * Allocates a new ByteBuffer to receive the message
                     */
            byte[] msgArray = new byte[length];
            // 从socket中读取数据，包装成buffer
            din.readFully(msgArray, 0, length);
            ByteBuffer message = ByteBuffer.wrap(msgArray);
            // 包装成messeage 加入队列
            addToRecvQueue(new Message(message.duplicate(), sid));
        }
    } catch (Exception e) {
        LOG.warn("Connection broken for id " + sid + ", my id = "
                 + QuorumCnxManager.this.mySid + ", error = " , e);
    } finally {
        LOG.warn("Interrupting SendWorker");
        sw.finish();
        if (sock != null) {
            closeSocket(sock);
        }
    }
}
````

![1569316206356](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1569316206356.png)

回到主流程，这个FastLeaderElection类是最重要的

````java
public FastLeaderElection(QuorumPeer self, QuorumCnxManager manager){
    this.stop = false;
    this.manager = manager;
    // 初始化sendqueue、recvqueue 并且启动WorkerSender和WorkerReceiver线程
    starter(self, manager);
}
````

````java
private void starter(QuorumPeer self, QuorumCnxManager manager) {
        this.self = self;
        proposedLeader = -1;
        proposedZxid = -1;
	   // 创建两个队列
        sendqueue = new LinkedBlockingQueue<ToSend>();
        recvqueue = new LinkedBlockingQueue<Notification>();
        this.messenger = new Messenger(manager);
    }
````

````java
/**
	内部类

**/
Messenger(QuorumCnxManager manager) {
	// 创建线程
    this.ws = new WorkerSender(manager);

    Thread t = new Thread(this.ws,
                          "WorkerSender[myid=" + self.getId() + "]");
    // 守护线程，如果GC的时候只有守护线程，就直接回收，如果没有没有就等工作线程结束再回收
    t.setDaemon(true);
    t.start();
	// 同样创建一个线程
    this.wr = new WorkerReceiver(manager);

    t = new Thread(this.wr,
                   "WorkerReceiver[myid=" + self.getId() + "]");
    t.setDaemon(true);
    t.start();
}
````

WorkerSender#run

````java
public void run() {
                while (!stop) {
                    try {
                        ToSend m = sendqueue.poll(3000, TimeUnit.MILLISECONDS);
                        if(m == null) continue;

                        process(m);
                    } catch (InterruptedException e) {
                        break;
                    }
                }
                LOG.info("WorkerSender is down");
            }


void process(ToSend m) {
                ByteBuffer requestBuffer = buildMsg(m.state.ordinal(), 
                                                        m.leader,
                                                        m.zxid, 
                                                        m.electionEpoch, 
                                                        m.peerEpoch);
                manager.toSend(m.sid, requestBuffer);
            }
````

所以sendqueue里面的信息通过WorkerSender发送，同理WorkerReceiver是取出数据再处理，如下图

![1569317163128](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1569317163128.png)

**所以说QuorumCnxManager是传输层**

从上面代码可以看出startLeaderElection();方法已经结束，真正领导者选举其实是QuorumPeer的run方法

````java
 @Override
public synchronized void start() {
    // 加载数据
    loadDataBase();
    // 开启读取数据线程
    cnxnFactory.start();
    // 进行领导者选举，确定服务器的角色，再针对不同的服务器角色进行初始化
    startLeaderElection();
    // 本类的run方法
    super.start();
}
````

````java
public void run() {
    setName("QuorumPeer" + "[myid=" + getId() + "]" +
            cnxnFactory.getLocalAddress());

    LOG.debug("Starting quorum peer");
    try {
        jmxQuorumBean = new QuorumBean(this);
        MBeanRegistry.getInstance().register(jmxQuorumBean, null);
        // 循环所有server
        for(QuorumServer s: getView().values()){
            ZKMBeanInfo p;
            // 如果是自己
            if (getId() == s.id) {
                p = jmxLocalPeerBean = new LocalPeerBean(this);
                try {
                    MBeanRegistry.getInstance().register(p, jmxQuorumBean);
                } catch (Exception e) {
                    LOG.warn("Failed to register with JMX", e);
                    jmxLocalPeerBean = null;
                }
            } else {
                // 如果是同伴服务器
                p = new RemotePeerBean(s);
                try {
                    MBeanRegistry.getInstance().register(p, jmxQuorumBean);
                } catch (Exception e) {
                    LOG.warn("Failed to register with JMX", e);
                }
            }
        }
    } catch (Exception e) {
        LOG.warn("Failed to register with JMX", e);
        jmxQuorumBean = null;
    }

    try {
        /*
             * Main loop
             */
        while (running) {
            // 本机服务器状态
            switch (getPeerState()) {
                // 领导者选举进入这里
                case LOOKING:
                    LOG.info("LOOKING");
                    // 正在寻找leader

                    // 不关心只读服务器
                    if (Boolean.getBoolean("readonlymode.enabled")) {
                        LOG.info("Attempting to start ReadOnlyZooKeeperServer");


                        // Create read-only server but don't start it immediately
                        final ReadOnlyZooKeeperServer roZk = new ReadOnlyZooKeeperServer(
                            logFactory, this,
                            new ZooKeeperServer.BasicDataTreeBuilder(),
                            this.zkDb);

                        // Instead of starting roZk immediately, wait some grace
                        // period before we decide we're partitioned.
                        //
                        // Thread is used here because otherwise it would require
                        // changes in each of election strategy classes which is
                        // unnecessary code coupling.
                        Thread roZkMgr = new Thread() {
                            public void run() {
                                try {
                                    // lower-bound grace period to 2 secs
                                    sleep(Math.max(2000, tickTime));
                                    if (ServerState.LOOKING.equals(getPeerState())) {
                                        roZk.startup();
                                    }
                                } catch (InterruptedException e) {
                                    LOG.info("Interrupted while attempting to start ReadOnlyZooKeeperServer, not started");
                                } catch (Exception e) {
                                    LOG.error("FAILED to start ReadOnlyZooKeeperServer", e);
                                }
                            }
                        };
                        try {
                            roZkMgr.start();
                            setBCVote(null);
                            setCurrentVote(makeLEStrategy().lookForLeader());
                        } catch (Exception e) {
                            LOG.warn("Unexpected exception",e);
                            setPeerState(ServerState.LOOKING);
                        } finally {
                            // If the thread is in the the grace period, interrupt
                            // to come out of waiting.
                            roZkMgr.interrupt();
                            roZk.shutdown();
                        }
                    } else {
                        // 直接看这里
                        try {
                            // 兼容性代码
                            setBCVote(null);
                            setCurrentVote(makeLEStrategy().lookForLeader());
                        } catch (Exception e) {
                            LOG.warn("Unexpected exception", e);
                            setPeerState(ServerState.LOOKING);
                        }
                    }
                    break;
                case OBSERVING:
                    // 观察者
                    try {
                        LOG.info("OBSERVING");
                        // observer用到的两个CommitProcessor、SyncRequestProcessor
                        setObserver(makeObserver(logFactory));
                        observer.observeLeader();
                    } catch (Exception e) {
                        LOG.warn("Unexpected exception",e );                        
                    } finally {
                        observer.shutdown();
                        setObserver(null);
                        setPeerState(ServerState.LOOKING);
                    }
                    break;
                case FOLLOWING:
                    // 跟随者
                    try {
                        LOG.info("FOLLOWING");
                        setFollower(makeFollower(logFactory));
                        follower.followLeader();
                    } catch (Exception e) {
                        LOG.warn("Unexpected exception",e);
                    } finally {
                        follower.shutdown();
                        setFollower(null);
                        // 只要服务器在运行的过程中出现了异常就会设置成LOOKING状态
                        setPeerState(ServerState.LOOKING);
                    }
                    break;
                case LEADING:
                    LOG.info("LEADING");
                    // 领导者
                    try {
                        setLeader(makeLeader(logFactory));
                        // 主要就是开启LearnerHandler线程
                        leader.lead();
                        setLeader(null);
                    } catch (Exception e) {
                        LOG.warn("Unexpected exception",e);
                    } finally {
                        if (leader != null) {
                            leader.shutdown("Forcing shutdown");
                            setLeader(null);
                        }
                        setPeerState(ServerState.LOOKING);
                    }
                    break;
            }
        }
    } finally {
        LOG.warn("QuorumPeer main thread exited");
        try {
            MBeanRegistry.getInstance().unregisterAll();
        } catch (Exception e) {
            LOG.warn("Failed to unregister with JMX", e);
        }
        jmxQuorumBean = null;
        jmxLocalPeerBean = null;
    }
}
````

真正重要的方法：`setCurrentVote(makeLEStrategy().lookForLeader());`

````java
public Vote lookForLeader() throws InterruptedException {
        try {
            self.jmxLeaderElectionBean = new LeaderElectionBean();
            MBeanRegistry.getInstance().register(
                    self.jmxLeaderElectionBean, self.jmxLocalPeerBean);
        } catch (Exception e) {
            LOG.warn("Failed to register with JMX", e);
            self.jmxLeaderElectionBean = null;
        }
        if (self.start_fle == 0) {
           self.start_fle = Time.currentElapsedTime();
        }
        try {
            HashMap<Long, Vote> recvset = new HashMap<Long, Vote>(); //投票箱，key:其他服务器sid，Vote

            HashMap<Long, Vote> outofelection = new HashMap<Long, Vote>();

            int notTimeout = finalizeWait;

            synchronized(this){
                logicalclock.incrementAndGet(); // 时钟+1
                //更新提议，包含(myid,lastZxid,epoch)，更新为自己
                updateProposal(getInitId(), getInitLastLoggedZxid(), getPeerEpoch());
            }

            LOG.info("New election. My id =  " + self.getId() +
                    ", proposed zxid=0x" + Long.toHexString(proposedZxid));
            sendNotifications(); // 启动时先投票给自己

            /*
             * Loop in which we exchange notifications until we find a leader
             */

            while ((self.getPeerState() == ServerState.LOOKING) &&
                    (!stop)){ //只要没有停止，并且状态处于LOOKING状态
                /*
                 * Remove next notification from queue, times out after 2 times
                 * the termination time
                 * // 获取其他服务器的投票
                 */
                Notification n = recvqueue.poll(notTimeout,
                        TimeUnit.MILLISECONDS);

                /*
                 * Sends more notifications if haven't received enough.
                 * Otherwise processes new notification.
                 */
                if(n == null){
                    // 获取到的选票是空的，判断有没有需要发送的数据
                    // 因为之前已经sendNotifications过一次了（投票给自己），所以如果走到这里来，发现有东西没发送出去，那么可能的原因就是连接还没建立
                    if(manager.haveDelivered()){ // 如果都已经
                        sendNotifications();
                    } else {
                        // 连接所有可以投票的服务器,谁可以投票，
                        manager.connectAll();
                    }

                    /*
                     * Exponential backoff
                     */
                    int tmpTimeOut = notTimeout*2;
                    notTimeout = (tmpTimeOut < maxNotificationInterval?
                            tmpTimeOut : maxNotificationInterval);
                    LOG.info("Notification time out: " + notTimeout);
                }
                else if(validVoter(n.sid) && validVoter(n.leader)) {
                    // 如果接收到了结果
                    /*
                     * Only proceed if the vote comes from a replica in the
                     * voting view for a replica in the voting view.
                     */
                    switch (n.state) {
                    case LOOKING:
                        // 发送选票的服务器也在进行领导者选举
                        // If notification > current, replace and send messages out
                        if (n.electionEpoch > logicalclock.get()) { //如果接收到的投票轮次比自己的高
                            logicalclock.set(n.electionEpoch); // 设置自己的时钟为选票的时钟
                            recvset.clear(); // 清空自己的选票

                            // 比较选票对应的服务器和本机，如果选票对应的服务器更新就更新投票为选票所对应的服务器
                            if(totalOrderPredicate(n.leader, n.zxid, n.peerEpoch,
                                    getInitId(), getInitLastLoggedZxid(), getPeerEpoch())) {
                                updateProposal(n.leader, n.zxid, n.peerEpoch);
                            } else {
                                // 否则投给自己
                                updateProposal(getInitId(),
                                        getInitLastLoggedZxid(),
                                        getPeerEpoch());
                            }
                            // 发送投票
                            sendNotifications();
                        } else if (n.electionEpoch < logicalclock.get()) {
                            // 接受到的选票小于自己的时钟，放弃
                            if(LOG.isDebugEnabled()){
                                LOG.debug("Notification election epoch is smaller than logicalclock. n.electionEpoch = 0x"
                                        + Long.toHexString(n.electionEpoch)
                                        + ", logicalclock=0x" + Long.toHexString(logicalclock.get()));
                            }
                            break;
                        } else if (totalOrderPredicate(n.leader, n.zxid, n.peerEpoch,
                                proposedLeader, proposedZxid, proposedEpoch)) {
                            // 如果时钟相等，同样比较谁的服务器更新
                            updateProposal(n.leader, n.zxid, n.peerEpoch);
                            sendNotifications();
                        }

                        if(LOG.isDebugEnabled()){
                            LOG.debug("Adding vote: from=" + n.sid +
                                    ", proposed leader=" + n.leader +
                                    ", proposed zxid=0x" + Long.toHexString(n.zxid) +
                                    ", proposed election epoch=0x" + Long.toHexString(n.electionEpoch));
                        }
                        // 保存自己接受到的选票
                        recvset.put(n.sid, new Vote(n.leader, n.zxid, n.electionEpoch, n.peerEpoch));

                        // 根据接受到的选票，以及自己的投票，来判断能不能成为Leader
                        if (termPredicate(recvset,
                                new Vote(proposedLeader, proposedZxid,
                                        logicalclock.get(), proposedEpoch))) {
                            // 如果符合过半验证，本台服务器就认为选出了Leader

                            // Verify if there is any change in the proposed leader
                            while((n = recvqueue.poll(finalizeWait,
                                    TimeUnit.MILLISECONDS)) != null){
                                // 如果又接收到了选票，如果该选票比刚刚选出来的更优秀，则把该选票加入recvqueue中，并且退出这个while，退出这个while会继续走上层的while
                                // 这个地方的逻辑其实就是，我已经选出了一个Leader，但有过来的新的投票，如果说新票所对应的服务器没有我选出来的Leader优秀，那么不用管了，继续读取下一个选票进行同样的判断，
                                // 如果说新的投票所对应的服务器比我选出来的要优秀，那么重新把这个选票放回到recvqueue，并退出当前循环，进入上层循环，重新开始选举
                                // 如果不够优秀，则继续循环，直到没有获取到选票了
                                if(totalOrderPredicate(n.leader, n.zxid, n.peerEpoch,
                                        proposedLeader, proposedZxid, proposedEpoch)){
                                    recvqueue.put(n);
                                    break;
                                }
                            }

                            /*
                             * This predicate is true once we don't read any new
                             * relevant message from the reception queue
                             */
                            if (n == null) {
                                // 如果没有获取到选票了，那么Leader也就选出来了
                                // 如果选出来的是自己，就将自己设置为LEADING, 如果是其他服务器，就将自己设置为对应的状态
                                self.setPeerState((proposedLeader == self.getId()) ?
                                        ServerState.LEADING: learningState());

                                // 将本服务器最终的投票返回
                                Vote endVote = new Vote(proposedLeader,
                                                        proposedZxid,
                                                        logicalclock.get(),
                                                        proposedEpoch);
                                leaveInstance(endVote);
                                return endVote;
                            }
                        }
                        break;
                    case OBSERVING:
                        LOG.debug("Notification from observer: " + n.sid);
                        break;
                    case FOLLOWING:
                    case LEADING:
                        /*
                         * Consider all notifications from the same epoch
                         * together.
                         */
                        if(n.electionEpoch == logicalclock.get()){
                            recvset.put(n.sid, new Vote(n.leader,
                                                          n.zxid,
                                                          n.electionEpoch,
                                                          n.peerEpoch));
                           
                            if(ooePredicate(recvset, outofelection, n)) {
                                self.setPeerState((n.leader == self.getId()) ?
                                        ServerState.LEADING: learningState());

                                Vote endVote = new Vote(n.leader, 
                                        n.zxid, 
                                        n.electionEpoch, 
                                        n.peerEpoch);
                                leaveInstance(endVote);
                                return endVote;
                            }
                        }

                        /*
                         * Before joining an established ensemble, verify
                         * a majority is following the same leader.
                         */
                        outofelection.put(n.sid, new Vote(n.version,
                                                            n.leader,
                                                            n.zxid,
                                                            n.electionEpoch,
                                                            n.peerEpoch,
                                                            n.state));
           
                        if(ooePredicate(outofelection, outofelection, n)) {
                            synchronized(this){
                                logicalclock.set(n.electionEpoch);
                                self.setPeerState((n.leader == self.getId()) ?
                                        ServerState.LEADING: learningState());
                            }
                            Vote endVote = new Vote(n.leader,
                                                    n.zxid,
                                                    n.electionEpoch,
                                                    n.peerEpoch);
                            leaveInstance(endVote);
                            return endVote;
                        }
                        break;
                    default:
                        LOG.warn("Notification state unrecognized: {} (n.state), {} (n.sid)",
                                n.state, n.sid);
                        break;
                    }
                } else {
                    if (!validVoter(n.leader)) {
                        LOG.warn("Ignoring notification for non-cluster member sid {} from sid {}", n.leader, n.sid);
                    }
                    if (!validVoter(n.sid)) {
                        LOG.warn("Ignoring notification for sid {} from non-quorum member sid {}", n.leader, n.sid);
                    }
                }
            }
            return null;
        } finally {
            try {
                if(self.jmxLeaderElectionBean != null){
                    MBeanRegistry.getInstance().unregister(
                            self.jmxLeaderElectionBean);
                }
            } catch (Exception e) {
                LOG.warn("Failed to unregister with JMX", e);
            }
            self.jmxLeaderElectionBean = null;
            LOG.debug("Number of connection processing threads: {}",
                    manager.getConnectionThreadCount());
        }
    }
````

1. recvqueu默认有一票，是自己，如果发送的票和自己相等不用通过socket,j就放进了recvqueu里面

2. 如果服务器状态处于LOOKING状态并且没有停止

   1. 从`recvqueu`队列里面拿出消息，如果没有，判断之前发送的消息有没有发出去

      1. 判断的时候是拿出发送数据的Map即`queueSendMap`中的发送队列的数据，如果队列数据为空，则发送，发送时取出配置的集群服务器信息，构建消息，放入发送队列
      2. 如果发送数据的Map中的队列有数据，就说明可能还没有连上其他服务器，于是连接所有可以投票的服务器
      3. 通过sid和选举地址连接以及socket连接其他服务器
      4. 连接后进行连接初始化
         1. 如果对方的sid大于我的myid就关闭连接
         2. 连接成功就初始化SendWorker和RecvWorker两个线程并启动，这两个线程主要去发送和接受服务器的数据【前面有分析过】

   2. 如果对方发过来的sid和选举的leader的id没有问题

      1. 如果服务器依旧处于LOOKING状态

         1. 如果接收到的投票轮次比自己的高，即选举周期比自己大的

            1. 将我的轮次更新为对方的轮次，比较选票对应的服务器和本机，如果选票对应的服务器更新就更新投票为选票所对应的服务器
            2. 否则投给自己
            3. 发送投票

         2. 接受到的选票小于自己的时钟，放弃

         3. 如果对方的选举周期比自己告或者对方的zxid比我的大，或者myid比我大就将我的选票更新为对方的选票，然后发送

            ```java
            return ((newEpoch > curEpoch) || 
                            ((newEpoch == curEpoch) &&
                            ((newZxid > curZxid) || ((newZxid == curZxid) && (newId > curId)))));
            ```

         4. 保存自己接受到的选票到投票箱

         5. 根据接受到的选票，以及自己的投票，来判断能不能成为Leader

            1. 将当前主机的投票箱和自己投的票相同的过滤，然后判断是否过半，如果过半，那么自己
            2. 判断队列还有没有其他数据，如果有新的选票和我自己选的leader比较，如果自己没有刚接受的选票优秀就继续循环 直到没有获取到选票了

         6. 如果没有获取到选票了，那么Leader也就选出来了，如果选出来的是自己，就将自己设置为LEADING, 如果是其他服务器，就将自己设置为对应的状态， 将本服务器最终的投票返回

      2. 

   3. 

3. 

## 如果启动之后，服务器挂掉了怎么办

### 源码分析

如果是leader挂了之后，两个follower因为要很leader进行数据同步所以在同步的地方会报异常，然后就被会设置为LOOKING状态，后接着上面的流程选举

````java
case FOLLOWING:
    // 跟随者
    try {
        LOG.info("FOLLOWING");
        setFollower(makeFollower(logFactory));
        // 同步数据Zab协议
        follower.followLeader();
    } catch (Exception e) {
        LOG.warn("Unexpected exception",e);
    } finally {
        follower.shutdown();
        setFollower(null);
        // 只要服务器在运行的过程中出现了异常就会设置成LOOKING状态
        setPeerState(ServerState.LOOKING);
    }
    break;
````

其实是在leader.readPacket的时候报出异常，因为socket断了，所以报错，然后上层抓到异常

**如果是Follower挂掉了怎么办？**

在leader服务器启动服务后，也就是startServer()后，下面的代码就判断和其他服务器的连接是否符合过半机制

leader#lead()

````java
// 初始化
startZkServer();

boolean tickSkip = true;
    
while (true) {
    Thread.sleep(self.tickTime / 2);
    if (!tickSkip) {
        self.tick.incrementAndGet();
    }
    HashSet<Long> syncedSet = new HashSet<Long>();

    // lock on the followers when we use it.
    syncedSet.add(self.getId());

    for (LearnerHandler f : getLearners()) {
        // Synced set is used to check we have a supporting quorum, so only
        // PARTICIPANT, not OBSERVER, learners should be used
        if (f.synced() && f.getLearnerType() == LearnerType.PARTICIPANT) {
            syncedSet.add(f.getSid());
        }
        f.ping();
    }

    // check leader running status
    if (!this.isRunning()) {
        shutdown("Unexpected internal error");
        return;
    }

    if (!tickSkip && !self.getQuorumVerifier().containsQuorum(syncedSet)) {
        //if (!tickSkip && syncedCount < self.quorumPeers.size() / 2) {
        // Lost quorum, shutdown
        shutdown("Not sufficient followers synced, only synced with sids: [ "
                 + getSidSetString(syncedSet) + " ]");
        // make sure the order is the same!
        // the leader goes to looking
        return;
    } 
    tickSkip = !tickSkip;
}
````

如果不满足过半，就shutdown，shutdown完后程序继续执行，在finally里面关闭leader，以及重新选举

````java
case LEADING:
    LOG.info("LEADING");
    // 领导者
    try {
        setLeader(makeLeader(logFactory));
        // 主要就是开启LearnerHandler线程
        leader.lead();
        setLeader(null);
    } catch (Exception e) {
        LOG.warn("Unexpected exception",e);
    } finally {
        if (leader != null) {
            leader.shutdown("Forcing shutdown");
            setLeader(null);
        }
        // 设置服务器状态为LOOKING
        setPeerState(ServerState.LOOKING);
    }
    break;
}
````

**如果中间加入一个服务器**

新加入的服务器将自己的投票发送给其他服务器，其他服务器已经选举好了，它们判断这个服务器还是LOOKING状态就会把leader的信息包装成最终的选票发送给它，新服务器接受到信息就会去和leader连接。

WorkerReceiver#run

````java
public void run() {

    Message response;
    while (!stop) {
        // Sleeps on receive
        try{
            response = manager.pollRecvQueue(3000, TimeUnit.MILLISECONDS);
            if(response == null) continue;

            /*
                         * If it is from an observer, respond right away.
                         * Note that the following predicate assumes that
                         * if a server is not a follower, then it must be
                         * an observer. If we ever have any other type of
                         * learner in the future, we'll have to change the
                         * way we check for observers.
                         */
            if(!validVoter(response.sid)){
                // 不是合法的投票者，那么它就是observer，把自己当前的投票告诉他
                Vote current = self.getCurrentVote();
                ToSend notmsg = new ToSend(ToSend.mType.notification,
                                           current.getId(),
                                           current.getZxid(),
                                           logicalclock.get(),
                                           self.getPeerState(),
                                           response.sid,
                                           current.getPeerEpoch());

                sendqueue.offer(notmsg);
            } else {
                // Receive new message
                if (LOG.isDebugEnabled()) {
                    LOG.debug("Receive new notification message. My id = "
                              + self.getId());
                }

                /*
                             * We check for 28 bytes for backward compatibility
                             */
                if (response.buffer.capacity() < 28) {
                    LOG.error("Got a short response: "
                              + response.buffer.capacity());
                    continue;
                }
                boolean backCompatibility = (response.buffer.capacity() == 28);
                response.buffer.clear();

                // Instantiate Notification and set its attributes
                Notification n = new Notification();

                // State of peer that sent this message
                // 对方的服务器状态
                QuorumPeer.ServerState ackstate = QuorumPeer.ServerState.LOOKING;
                switch (response.buffer.getInt()) {
                    case 0:
                        ackstate = QuorumPeer.ServerState.LOOKING;
                        break;
                    case 1:
                        ackstate = QuorumPeer.ServerState.FOLLOWING;
                        break;
                    case 2:
                        ackstate = QuorumPeer.ServerState.LEADING;
                        break;
                    case 3:
                        ackstate = QuorumPeer.ServerState.OBSERVING;
                        break;
                    default:
                        continue;
                }

                n.leader = response.buffer.getLong();
                n.zxid = response.buffer.getLong();
                n.electionEpoch = response.buffer.getLong();
                n.state = ackstate;
                n.sid = response.sid;
                if(!backCompatibility){
                    n.peerEpoch = response.buffer.getLong();
                } else {
                    if(LOG.isInfoEnabled()){
                        LOG.info("Backward compatibility mode, server id=" + n.sid);
                    }
                    n.peerEpoch = ZxidUtils.getEpochFromZxid(n.zxid);
                }

                /*
                             * Version added in 3.4.6
                             */

                n.version = (response.buffer.remaining() >= 4) ? 
                    response.buffer.getInt() : 0x0;

                /*
                             * Print notification info
                             */
                if(LOG.isInfoEnabled()){
                    printNotification(n);
                }

                /*
                             * If this server is looking, then send proposed leader
                             */
                // 如果自己是LOOKING状态，代表正在进行领导选举
                if(self.getPeerState() == QuorumPeer.ServerState.LOOKING){
                    recvqueue.offer(n);

                    /*
                                 * Send a notification back if the peer that sent this
                                 * message is also looking and its logical clock is
                                 * lagging behind.
                                 */
                    if((ackstate == QuorumPeer.ServerState.LOOKING)
                       && (n.electionEpoch < logicalclock.get())){
                        Vote v = getVote();
                        ToSend notmsg = new ToSend(ToSend.mType.notification,
                                                   v.getId(),
                                                   v.getZxid(),
                                                   logicalclock.get(),
                                                   self.getPeerState(),
                                                   response.sid,
                                                   v.getPeerEpoch());
                        sendqueue.offer(notmsg);
                    }
                } else {
                    /*
                     * If this server is not looking, but the one that sent the ack
                     * is looking, then send back what it believes to be the leader.
                     */
                    // 如果自己现在不是LOOKING状态, 那么有可能自己是Leader，或自己是Follower
                    // 那么就把他认为的Leader作为投票发送出去

                    Vote current = self.getCurrentVote();
                    if(ackstate == QuorumPeer.ServerState.LOOKING){
                        if(LOG.isDebugEnabled()){
                            LOG.debug("Sending new notification. My id =  " +
                                      self.getId() + " recipient=" +
                                      response.sid + " zxid=0x" +
                                      Long.toHexString(current.getZxid()) +
                                      " leader=" + current.getId());
                        }

                        ToSend notmsg;
                        if(n.version > 0x0) {
                            notmsg = new ToSend(
                                ToSend.mType.notification,
                                current.getId(),
                                current.getZxid(),
                                current.getElectionEpoch(),
                                self.getPeerState(),
                                response.sid,
                                current.getPeerEpoch());

                        } else {
                            // 包装成最终投票发给新的服务器
                            Vote bcVote = self.getBCVote();
                            notmsg = new ToSend(
                                ToSend.mType.notification,
                                bcVote.getId(),
                                bcVote.getZxid(),
                                bcVote.getElectionEpoch(),
                                self.getPeerState(),
                                response.sid,
                                bcVote.getPeerEpoch());
                        }
                        sendqueue.offer(notmsg);
                    }
                }
            }
        } catch (InterruptedException e) {
            System.out.println("Interrupted Exception while waiting for new message" +
                               e.toString());
        }
    }
    LOG.info("WorkerReceiver is down");
}
}
````

